{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 - Lexical Semantic\n",
    "Natural Language Processing - Universidad Tecnol√≥gica Nacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.book import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('dog.n.01'),\n",
       " Synset('frump.n.01'),\n",
       " Synset('dog.n.03'),\n",
       " Synset('cad.n.01'),\n",
       " Synset('frank.n.02'),\n",
       " Synset('pawl.n.01'),\n",
       " Synset('andiron.n.01'),\n",
       " Synset('chase.v.01')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Synsets of dog\n",
    "wn.synsets('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('chase.v.01')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filtering synsets by part of speech\n",
    "wn.synsets('dog', pos=wn.VERB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('dog.n.01')\n",
      "Synset('frump.n.01')\n",
      "Synset('frump.n.01')\n"
     ]
    }
   ],
   "source": [
    "print(wn.synset('dog.n.01'))\n",
    "print(wn.synset('dog.n.02'))\n",
    "print(wn.synset('frump.n.01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds\n",
      "a dull unattractive unpleasant girl or woman\n",
      "a dull unattractive unpleasant girl or woman\n"
     ]
    }
   ],
   "source": [
    "print(wn.synset('dog.n.01').definition())\n",
    "print(wn.synset('dog.n.02').definition())\n",
    "print(wn.synset('frump.n.01').definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('dog.n.01.dog'),\n",
       " Lemma('dog.n.01.domestic_dog'),\n",
       " Lemma('dog.n.01.Canis_familiaris')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Synset synonyms\n",
    "wn.synset('dog.n.01').lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the dog barked all night']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Synset examples\n",
    "wn.synset('dog.n.01').examples()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationships between words in WordNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog = wn.synset('dog.n.01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('canine.n.02'), Synset('domestic_animal.n.01')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hypernyms of dog\n",
    "dog.hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('basenji.n.01'),\n",
       " Synset('corgi.n.01'),\n",
       " Synset('cur.n.01'),\n",
       " Synset('dalmatian.n.02'),\n",
       " Synset('great_pyrenees.n.01'),\n",
       " Synset('griffon.n.02'),\n",
       " Synset('hunting_dog.n.01'),\n",
       " Synset('lapdog.n.01'),\n",
       " Synset('leonberg.n.01'),\n",
       " Synset('mexican_hairless.n.01'),\n",
       " Synset('newfoundland.n.01'),\n",
       " Synset('pooch.n.01'),\n",
       " Synset('poodle.n.01'),\n",
       " Synset('pug.n.01'),\n",
       " Synset('puppy.n.01'),\n",
       " Synset('spitz.n.01'),\n",
       " Synset('toy_dog.n.01'),\n",
       " Synset('working_dog.n.01')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyponyms of dog\n",
    "dog.hyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Synset of good as an adjective\n",
    "good = wn.synset('good.a.01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('good.a.01.good')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good.lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('bad.a.01.bad')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Antonyms of good\n",
    "g0 = good.lemmas()[0]\n",
    "g0.antonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('flag.n.07')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.part_meronyms() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.member_meronyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.part_holonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('canis.n.01'), Synset('pack.n.06')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.member_holonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('canis.n.01'), Synset('pack.n.06')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.member_holonyms()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flag.n.07 is part of dog.n.01, dog.n.01 is member of canis.n.01 and pack.n.06"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word sense desambiguation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The bank can guarantee deposits will eventually cover future tuition costs because it invests in adjustable-rate mortgage securities.\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Bank* could have differents meanings. It could be a financial institution or the land alongside to a river or lake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('bank.n.01'),\n",
       " Synset('depository_financial_institution.n.01'),\n",
       " Synset('bank.n.03'),\n",
       " Synset('bank.n.04'),\n",
       " Synset('bank.n.05'),\n",
       " Synset('bank.n.06'),\n",
       " Synset('bank.n.07'),\n",
       " Synset('savings_bank.n.02'),\n",
       " Synset('bank.n.09'),\n",
       " Synset('bank.n.10'),\n",
       " Synset('bank.v.01'),\n",
       " Synset('bank.v.02'),\n",
       " Synset('bank.v.03'),\n",
       " Synset('bank.v.04'),\n",
       " Synset('bank.v.05'),\n",
       " Synset('deposit.v.02'),\n",
       " Synset('bank.v.07'),\n",
       " Synset('trust.v.01')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Looking for synsets of bank\n",
    "wn.synsets('bank')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Bank* appears many times as a noun and as a verb. Also its appears with different meanings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lesk algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('bank.n.05')\n"
     ]
    }
   ],
   "source": [
    "from nltk.wsd import lesk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text_tokens = word_tokenize(text)\n",
    "print(lesk(text_tokens, 'bank', 'n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a supply or stock held in reserve for future use (especially in emergencies)'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('bank.n.05').definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'future', 'in'}\n",
      "{'deposits'}\n"
     ]
    }
   ],
   "source": [
    "l = word_tokenize(wn.synset('bank.n.05').definition())\n",
    "m =\tword_tokenize((wn.synset('bank.n.02').definition()))\t\n",
    "\n",
    "k = set(text_tokens)\n",
    "print(k.intersection(l))\n",
    "print(k.intersection(m))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm chose *bank.n.05* because its intersection between tokens from the text and tokens from its definition is bigger compared to others intersections. Maybe removing stop words could lead to better results. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Looking for the right meaning of this sentences:\n",
    "\n",
    "\n",
    "   **1.** I went to the bank to deposit some money.\\\n",
    "   **2.** She created a big mess of the birthday cake.\\\n",
    "   **3.** In the interest of your safety, please wear your seatbelt.\\\n",
    "   **4.** I drank some ice cold water."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** It's refers to a person who had went to a financial institution to save its money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('savings_bank.n.02')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lesk(word_tokenize(\"I went to the bank to deposit some money\"), 'bank', 'n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a container (usually with a slot in the top) for keeping money at home'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('savings_bank.n.02').definition()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** It's refers to a girl that had made a disorder with its birthday cake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('mess.n.04')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lesk(word_tokenize(\"She created a big mess of the birthday cake\"), 'mess', 'n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a meal eaten in a mess hall by service personnel'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('mess.n.04').definition()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** If want to be safety, you should wear your seatbelt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('interest.v.01')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lesk(word_tokenize(\"In the interest of your safety, please wear your seatbelt\"), 'interest', 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'excite the curiosity of; engage the interest of'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('interest.v.01').definition()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** That the person had drank very cold water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('toast.v.02')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lesk(word_tokenize(\"I drank some ice cold water\"), 'drank', 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'propose a toast to'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('toast.v.02').definition()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The closest predictions were for interest and bank, but actually, they were wrong."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lesk and Lemmatization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:**\n",
    "\n",
    "Can\tyou\timprove\tthe\tLesk\talgorithm\tusing\ta\tlemmatizer?\tIf\tso,\tcan\tyou\twrite\ta\tfunction\tmatch\twhich\t\n",
    "takes\ttwo\tstrings\tand\treturns\tthe\tmatching\twords\tbetween\tthem.\tWe\twant\tthe\tmatches\tto\tbe\tuseful\tfor\tan\t\n",
    "algorithm\tsuch\tas\tLesk.\tMaybe\tyou\talso\tneed\tto\trun\ta\tsimple\tPOS\ttagger?\tUse\tcan use\tan\tinbuilt\tPOS\t\n",
    "tagger\tin\tWordNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'money'}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def wanted_token(word):\n",
    "\n",
    "    #Filtering tokens\n",
    "    return not (word in stop_words or word in string.punctuation)\n",
    "\n",
    "def lemma_pos(word_and_pos):\n",
    "\n",
    "    #Lemmatization by part of speech\n",
    "    word, pos = word_and_pos\n",
    "    if pos.startswith('N'):\n",
    "        return lemmatizer.lemmatize(word, 'n')\n",
    "    elif pos.startswith('V'):\n",
    "        return lemmatizer.lemmatize(word, 'v')\n",
    "    elif pos.startswith('J'):\n",
    "        return lemmatizer.lemmatize(word, 'a')\n",
    "    elif pos.startswith('R'):\n",
    "        return lemmatizer.lemmatize(word, 'r')\n",
    "    else:\n",
    "        return lemmatizer.lemmatize(word)\n",
    "\n",
    "def matcher(first_string, second_string):\n",
    "    \n",
    "    #Part of speech tagging\n",
    "    first_pos = pos_tag(word_tokenize(first_string.lower()))\n",
    "    second_pos = pos_tag(word_tokenize(second_string.lower()))\n",
    "\n",
    "    #Lemmatization\n",
    "    first_lemma = [lemma_pos(word) for word in first_pos if wanted_token(word[0])]\n",
    "    second_lemma = [lemma_pos(word) for word in second_pos if wanted_token(word[0])]\n",
    "\n",
    "    #Intersection of lemmatized strings\n",
    "    intersection = set(first_lemma).intersection(set(second_lemma))\n",
    "    return intersection\n",
    "\n",
    "matcher(\"I went to the bank to deposit some money.\", \"She created a big mess of the birthday money cake.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
